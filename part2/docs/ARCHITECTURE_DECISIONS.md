# Architecture Decision Records (ADR)

## Contexto Geral

Este documento regista as principais decis√µes arquiteturais tomadas no desenvolvimento do sistema de recomenda√ß√µes LLM-Driven para produtos Nintendo Switch. O objetivo √© documentar n√£o apenas o que foi escolhido, mas tamb√©m **o que foi rejeitado e porqu√™**.

---

## ADR-001: Arquitetura H√≠brida - Function Calling + LangChain SQL Agent

**Data:** 2024-11-24  
**Status:** ‚úÖ ACEITE (implementa√ß√£o em 2 fases)  
**Decisores:** Equipa de Engenharia

### Problema

Como permitir que o LLM aceda a dados estruturados (PostgreSQL) de forma:
- **Flex√≠vel:** Suportar queries diversas e imprevistas
- **Segura:** Sem risco de SQL injection ou queries perigosas
- **Escal√°vel:** Funcionar com 100 produtos e com 100.000 produtos
- **Control√°vel:** N√£o inventar dados quando n√£o tem ferramentas adequadas

### Op√ß√µes Consideradas

#### ‚ùå Op√ß√£o 1: Function Calling Puro (OpenAI)

**Descri√ß√£o:** Definir explicitamente 5-10 ferramentas que o LLM pode chamar.

**Exemplo:**
```python
tools = [
    {"name": "search_products", "parameters": {"store": str, "max_age": int, ...}},
    {"name": "get_product_details", "parameters": {"product_id": int}},
    {"name": "get_cooccurrence_neighbors", "parameters": {"product_id": int}}
]
```

**Pr√≥s:**
- ‚úÖ **Controlo total** sobre queries executadas
- ‚úÖ **Seguran√ßa m√°xima** (queries validadas manualmente)
- ‚úÖ **Performance otimizada** (queries escritas √† m√£o)
- ‚úÖ **F√°cil debugging** e testes
- ‚úÖ **Custo previs√≠vel** (chamadas LLM controladas)

**Contras:**
- ‚ùå **Inflex√≠vel** - precisa prever todas as queries poss√≠veis
- ‚ùå **Manuten√ß√£o alta** - adicionar ferramentas constantemente
- ‚ùå **N√£o escala** para casos edge (queries √∫nicas/complexas)
- ‚ùå **User frustration** quando query n√£o √© suportada

**Exemplo de Falha:**
```
User: "Qual a percentagem de jogos indie vs AAA na Store A?"
Agent: "Desculpa, n√£o consigo calcular percentagens." ‚ùå
```

**Veredicto:** ‚ö†Ô∏è Aceite para **MVP/Fase 1**, mas insuficiente para produ√ß√£o.

---

#### ‚ùå Op√ß√£o 2: RAG (Retrieval-Augmented Generation) Puro

**Descri√ß√£o:** Embeddings de descri√ß√µes de produtos + vector search para similaridade sem√¢ntica.

**Fluxo:**
```
User Query ‚Üí Embedding ‚Üí Vector Search ‚Üí Top-K produtos ‚Üí LLM gera resposta
```

**Pr√≥s:**
- ‚úÖ **Excelente para similaridade sem√¢ntica** ("jogos parecidos com X")
- ‚úÖ **Busca por descri√ß√µes** ("jogos relaxantes", "aventuras √©picas")
- ‚úÖ **R√°pido** com √≠ndices vetoriais (pgvector, Pinecone)

**Contras:**
- ‚ùå **N√£o aproveita dados estruturados** (min_age, store_a/b/c como colunas)
- ‚ùå **Queries num√©ricas imprecisas** (ex: "idade <= 7" depende de texto)
- ‚ùå **N√£o faz agrega√ß√µes** (COUNT, AVG, SUM)
- ‚ùå **N√£o faz filtros complexos** (exclus√µes, m√∫ltiplos ANDs)

**Exemplo de Falha:**
```
User: "Quantos jogos temos para menores de 7 anos na Store A?"
RAG: Busca docs similares, mas n√£o consegue fazer COUNT WHERE age <= 7 AND store_a > 0 ‚ùå
```

**Veredicto:** ‚ùå Rejeitado como solu√ß√£o √∫nica, mas **√∫til como componente** para similaridade.

---

#### ‚ùå Op√ß√£o 3: LangChain SQL Agent Puro

**Descri√ß√£o:** Agent que analisa o schema da DB e gera SQL dinamicamente.

**Exemplo:**
```python
from langchain.agents import create_sql_agent

agent = create_sql_agent(llm=llm, db=db)
agent.run("Jogos para menores de 7 anos na Store A")

# Internamente gera:
# SELECT * FROM products WHERE min_age <= 7 AND store_a > 0
```

**Pr√≥s:**
- ‚úÖ **Extremamente flex√≠vel** - n√£o precisa prever queries
- ‚úÖ **Suporta queries complexas** (agrega√ß√µes, joins, subqueries)
- ‚úÖ **Setup r√°pido** (3 linhas de c√≥digo)
- ‚úÖ **Escala naturalmente** com novas colunas/tabelas

**Contras:**
- ‚ùå **Menos controlo** sobre SQL gerado
- ‚ùå **Risco de queries ineficientes** (sem √≠ndices, full table scans)
- ‚ùå **Poss√≠vel SQL injection** se n√£o validado
- ‚ùå **N√£o faz busca sem√¢ntica** (n√£o usa embeddings)
- ‚ùå **Depend√™ncia de framework externo**

**Exemplo de Falha:**
```
User: "Jogos parecidos com Mario Odyssey"
SQL Agent: SELECT * FROM products WHERE name LIKE '%Mario%' ‚ùå (n√£o entende "parecido")
```

**Veredicto:** ‚ùå Rejeitado como solu√ß√£o √∫nica, mas **√∫til como fallback** para edge cases.

---

#### ‚úÖ Op√ß√£o 4: Arquitetura H√≠brida (ESCOLHIDO)

**Descri√ß√£o:** Combinar os pontos fortes de cada abordagem em camadas.

**Arquitetura:**

```
                    User Query
                         ‚Üì
        ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
        ‚îÇ    Intent Classification       ‚îÇ
        ‚îÇ    (LLM analisa tipo query)    ‚îÇ
        ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                     ‚Üì
         ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
         ‚îÇ                        ‚îÇ
    Structured              Semantic/Complex
    (filtros, IDs)         (descri√ß√µes, edge cases)
         ‚îÇ                        ‚îÇ
         ‚Üì                        ‚Üì
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê      ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ Function Tools  ‚îÇ      ‚îÇ Fallback Layer   ‚îÇ
‚îÇ (80% queries)   ‚îÇ      ‚îÇ (20% queries)    ‚îÇ
‚îÇ                 ‚îÇ      ‚îÇ                  ‚îÇ
‚îÇ - search_prod   ‚îÇ      ‚îÇ - Vector Search  ‚îÇ
‚îÇ - get_details   ‚îÇ      ‚îÇ   (similaridade) ‚îÇ
‚îÇ - cooccurrence  ‚îÇ      ‚îÇ - SQL Agent      ‚îÇ
‚îÇ - clarify       ‚îÇ      ‚îÇ   (queries adhoc)‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò      ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
         ‚îÇ                        ‚îÇ
         ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                      ‚Üì
            ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
            ‚îÇ Result Combiner ‚îÇ
            ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                     ‚Üì
            ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
            ‚îÇ Final Response  ‚îÇ
            ‚îÇ (LLM synthesis) ‚îÇ
            ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
```

**Implementa√ß√£o em 2 Fases:**

**Fase 1 (MVP - ATUAL):**
- ‚úÖ Function Calling com 5 ferramentas core
- ‚úÖ System prompt forte que admite limita√ß√µes
- ‚úÖ Ferramenta de "ask_for_clarification" para casos amb√≠guos
- ‚ùå Sem SQL Agent (complexidade reduzida)
- ‚ùå Sem embeddings (co-occurrence serve de proxy)

**Fase 2 (Produ√ß√£o - FUTURO):**
- ‚úÖ Adiciona LangChain SQL Agent como fallback
- ‚úÖ Adiciona vector search para similaridade sem√¢ntica
- ‚úÖ Logging de fallbacks ‚Üí cria novas ferramentas para padr√µes comuns
- ‚úÖ Caching de queries frequentes

**Decis√£o de Routing:**
```python
def route_query(query: str, intent: UserIntent) -> str:
    # Queries estruturadas simples ‚Üí Function Calling
    if intent.has_simple_filters():
        return "function_calling"
    
    # Queries sem√¢nticas ‚Üí Vector Search
    if "similar" in query or "like" in query or "parecido" in query:
        return "vector_search"
    
    # Queries complexas/√∫nicas ‚Üí SQL Agent
    if intent.requires_aggregation() or intent.is_complex():
        return "sql_agent"
    
    # Default
    return "function_calling"
```

### Consequ√™ncias

**Positivas:**
- ‚úÖ **Controlo total no MVP** (function calling)
- ‚úÖ **Path claro para escalar** (adicionar layers conforme necess√°rio)
- ‚úÖ **N√£o inventa dados** (admite limita√ß√µes)
- ‚úÖ **Aprende com uso real** (logs revelam patterns)
- ‚úÖ **Cada layer tem responsabilidade clara**

**Negativas:**
- ‚ùå **Mais c√≥digo** para manter (3 estrat√©gias)
- ‚ùå **Complexidade de routing** (decidir qual layer usar)
- ‚ùå **Precisa monitoring** robusto para identificar padr√µes

**Riscos Mitigados:**
- Function calling evita SQL injection ‚úÖ
- Embeddings (Fase 2) melhoram recomenda√ß√µes al√©m de co-occurrence ‚úÖ
- Fallback previne respostas "n√£o consigo ajudar" ‚úÖ

**M√©tricas de Sucesso:**
- 80%+ queries resolvidas por function calling
- Lat√™ncia < 500ms para queries comuns
- 0 casos de SQL injection
- Customer satisfaction > 4/5

---

## ADR-002: Estrat√©gia de Embeddings e Text Blob

**Data:** 2024-11-24  
**Status:** ‚è∏Ô∏è ADIADO para Fase 2  
**Decisores:** Equipa de Engenharia

### Problema

Produtos t√™m campo `text_blob` com descri√ß√µes. Quest√µes:
1. **O text_blob adiciona valor** ou √© redundante com conhecimento do LLM?
2. **Devemos implementar embeddings** no MVP?
3. **Que informa√ß√£o incluir** no text_blob para maximizar valor?

### An√°lise: Informa√ß√£o Redundante vs √önica

| Tipo de Informa√ß√£o | Exemplo | LLM j√° conhece? | Incluir no embedding? |
|-------------------|---------|-----------------|----------------------|
| Nome do jogo | "Super Mario Odyssey" | ‚úÖ Sim | ‚úÖ Sim (identificador) |
| Gameplay/Mec√¢nicas | "3D platformer where Mario uses Cappy to possess enemies" | ‚úÖ Sim (treino at√© 2023) | ‚ùå **N√ÉO** (redundante) |
| G√©nero | "Adventure, Platform" | ‚úÖ Sim | ‚úÖ Sim (estruturado) |
| Ano de lan√ßamento | "Released in 2017" | ‚úÖ Sim | ‚ùå N√ÉO (irrelevante para recomenda√ß√£o) |
| Publisher | "Nintendo" | ‚úÖ Sim | ‚ùå N√ÉO |
| **Co-occurrence** | "Frequently bought with Zelda BotW, Mario Kart 8" | ‚ùå **N√ÉO** | ‚úÖ **SIM** (√∫nico!) |
| **Customer insights** | "Most popular gift for ages 8-12, often for birthdays" | ‚ùå **N√ÉO** | ‚úÖ **SIM** (√∫nico!) |
| **Store exclusives** | "Store A exclusive: includes bonus amiibo card" | ‚ùå **N√ÉO** | ‚úÖ **SIM** (√∫nico!) |
| **Local availability** | "High stock at Store B, low at Store C" | ‚ùå **N√ÉO** | ‚úÖ **SIM** (√∫nico!) |

**Conclus√£o:** ~70% do text_blob t√≠pico √© **redundante**.

### Decis√£o: Text Blob Minimalista + Adiamento de Embeddings

#### **Para MVP (Fase 1):**

**Text Blob:**
- ‚ùå **Remover** descri√ß√µes de gameplay que o LLM j√° conhece
- ‚úÖ **Manter APENAS** informa√ß√£o comercial √∫nica:
  - Promo√ß√µes/bundles espec√≠ficos da loja
  - Customer insights ("popular gift for X demographics")
  - Cross-sell patterns ("bought with Y, Z")
  - Store exclusives

**Embeddings:**
- ‚è∏Ô∏è **N√ÉO implementar no MVP**
- Usar **co-occurrence** como proxy de similaridade
- Avaliar necessidade baseado em feedback real

**Rationale:**
1. MVP mais simples e r√°pido de implementar
2. Validar se users fazem queries sem√¢nticas frequentes
3. Co-occurrence j√° fornece "similar products" b√°sico
4. Economiza tokens e storage

#### **Para Produ√ß√£o (Fase 2):**

**Implementar embeddings SE:**
- ‚úÖ Text blobs forem enriquecidos com dados √∫nicos
- ‚úÖ Queries de "similaridade sem√¢ntica" forem >15% do total
- ‚úÖ Co-occurrence for insuficiente (e.g., novos produtos sem hist√≥rico)

**F√≥rmula do Embedding Text (quando implementar):**

```python
def create_embedding_text(product: dict, cooccurrence_top3: list) -> str:
    """
    Cria texto para embedding focado em informa√ß√£o √öNICA.
    """
    parts = [f"{product['name']} ({product['segment']}, {product['franchise']})"]
    
    # Co-occurrence insights
    if cooccurrence_top3:
        parts.append(
            f"Frequently bought with: {', '.join([p['name'] for p in cooccurrence_top3])}"
        )
    
    # Age demographic
    if product['min_age'] <= 7:
        parts.append("Popular with young children and families")
    elif product['min_age'] <= 12:
        parts.append("Popular with pre-teens")
    
    # Store context (se houver exclusives/promos)
    if product.get('store_exclusive_features'):
        parts.append(product['store_exclusive_features'])
    
    return ". ".join(parts)
```

**Exemplo Output:**
```
"Super Mario Odyssey (Games, Super Mario). 
Frequently bought with: Mario Kart 8, Zelda BotW, Splatoon 2. 
Popular with pre-teens. 
Store A exclusive: includes limited edition hat pin."
```

### Alternativas Rejeitadas

#### ‚ùå Op√ß√£o A: Embeddings desde o In√≠cio
- **Pr√≥s:** Similaridade sem√¢ntica desde dia 1
- **Contras:** Overhead t√©cnico, pode n√£o adicionar valor se text_blob for redundante
- **Decis√£o:** Adiado - validar necessidade primeiro

#### ‚ùå Op√ß√£o B: Text Blob Detalhado (gameplay completo)
- **Pr√≥s:** M√°xima informa√ß√£o
- **Contras:** 70% redundante, desperd√≠cio de tokens/storage
- **Decis√£o:** Rejeitado

#### ‚úÖ Op√ß√£o C: Text Blob Minimalista (ESCOLHIDO)
- **Pr√≥s:** Sem redund√¢ncia, foca em contexto √∫nico
- **Contras:** Requer curadoria de dados
- **Decis√£o:** Aceite com campos estruturados adicionais

### Consequ√™ncias

**Positivas:**
- ‚úÖ MVP mais simples (uma preocupa√ß√£o a menos)
- ‚úÖ N√£o gastamos tokens com info redundante
- ‚úÖ Path claro para adicionar embeddings baseado em dados reais

**Negativas:**
- ‚ùå Similaridade limitada a co-occurrence no MVP
- ‚ùå Queries tipo "jogos relaxantes" n√£o funcionam bem sem embeddings
- ‚ùå Cold start problem para produtos novos (sem co-occurrence)

---

## ADR-003: Escalabilidade para Milhares de Tabelas

**Data:** 2024-11-24  
**Status:** üìã PLANEAMENTO (n√£o aplic√°vel ao MVP)  
**Contexto:** Prepara√ß√£o para escala futura

### Problema

**Cen√°rio atual:** ~10 tabelas (products, cooccurrence, etc.)  
**Cen√°rio futuro hipot√©tico:** 1000+ tabelas em DB empresarial

**Desafio:**
```
Schema completo de 1000 tabelas: ~2.5 milh√µes de tokens
Context window GPT-4: 128k tokens
Resultado: Schema n√£o cabe! ‚ùå
```

Mesmo que coubesse, seria ineficiente (custo de tokens, lat√™ncia).

### Decis√£o: Estrat√©gia por Escala

#### **< 50 Tabelas (ATUAL):**
‚úÖ **Approach:** Schema completo no context

```python
agent = create_sql_agent(llm=llm, db=db)  # V√™ todas as tabelas
```

**Rationale:** Simples, funciona perfeitamente.

---

#### **50-500 Tabelas:**
‚úÖ **Approach:** Schema RAG (Retrieval-Augmented Generation)

**Implementa√ß√£o:**
```python
# 1. Criar embeddings do schema
schema_docs = []
for table in db.tables:
    doc = f"""
    Table: {table.name}
    Description: {table.comment}
    Columns: {', '.join([f"{c.name}({c.type})" for c in table.columns])}
    Common queries: {table.example_queries}
    Related tables: {table.foreign_keys}
    """
    schema_docs.append(doc)

# 2. Vector store do schema
schema_vectorstore = Pinecone.from_documents(
    schema_docs, 
    embeddings,
    namespace="db_schema"
)

# 3. Query flow
def smart_sql_agent(query: str):
    # 3a. RAG: Encontra tabelas relevantes
    relevant_tables = schema_vectorstore.similarity_search(query, k=5)
    
    # 3b. Cria mini-schema s√≥ com essas 5 tabelas
    mini_schema = {t.name: t.columns for t in relevant_tables}
    
    # 3c. SQL Agent v√™ apenas essas tabelas
    agent = create_sql_agent(
        llm=llm,
        db=db,
        include_tables=[t.name for t in relevant_tables]
    )
    
    return agent.run(query)
```

**Vantagens:**
- ‚úÖ Schema completo cabe no context (s√≥ 5 tabelas)
- ‚úÖ LLM v√™ apenas o relevante
- ‚úÖ Reduz tokens de 2.5M ‚Üí 10K
- ‚úÖ Mais r√°pido

**Exemplo:**
```
Query: "Jogos mais vendidos na Store A"

RAG encontra: [products, sales, stores, inventory, categories]
‚Üì
SQL Agent v√™ apenas essas 5 tabelas
‚Üì
Gera: SELECT p.name, SUM(s.quantity) FROM products p 
      JOIN sales s ON p.id = s.product_id 
      WHERE s.store_id = 'A'
      GROUP BY p.name ORDER BY SUM DESC LIMIT 10
```

---

#### **> 500 Tabelas:**
‚úÖ **Approach:** Hierarchical Routing + Schema RAG

**Implementa√ß√£o:**
```python
# 1. Organizar tabelas em dom√≠nios
domains = {
    "products": ["products", "categories", "brands", "inventory"],
    "sales": ["orders", "transactions", "revenue", "discounts"],
    "customers": ["users", "profiles", "addresses", "preferences"],
    "analytics": ["metrics", "kpis", "dashboards", "reports"]
}

# 2. Router identifica dom√≠nio
def route_to_domain(query: str) -> str:
    router_prompt = f"""
    Classify this query into a domain: {list(domains.keys())}
    
    Query: {query}
    """
    domain = llm.classify(router_prompt)
    return domain

# 3. Schema RAG dentro do dom√≠nio
def hierarchical_agent(query: str):
    # 3a. Identifica dom√≠nio (products, sales, etc.)
    domain = route_to_domain(query)
    
    # 3b. Schema RAG apenas nesse dom√≠nio
    domain_tables = domains[domain]
    relevant_tables = schema_rag_within_domain(query, domain_tables, k=5)
    
    # 3c. SQL Agent focado
    agent = create_sql_agent(llm, db, include_tables=relevant_tables)
    return agent.run(query)
```

**Vantagens:**
- ‚úÖ Escala para milhares de tabelas
- ‚úÖ Routing barato (classifica√ß√£o simples)
- ‚úÖ RAG focado (menos falsos positivos)

---

### Compara√ß√£o de Escalabilidade

| Approach | Max Tabelas | Tokens no Context | Lat√™ncia | Complexidade | Custo |
|----------|-------------|-------------------|----------|--------------|-------|
| Schema completo | ~50 | 50K | ‚≠ê‚≠ê‚≠ê‚≠ê‚≠ê | ‚≠ê | ‚≠ê‚≠ê‚≠ê‚≠ê‚≠ê |
| Schema RAG | ~500 | 10K | ‚≠ê‚≠ê‚≠ê‚≠ê | ‚≠ê‚≠ê‚≠ê | ‚≠ê‚≠ê‚≠ê‚≠ê |
| Hierarchical + RAG | 1000+ | 5K | ‚≠ê‚≠ê‚≠ê | ‚≠ê‚≠ê‚≠ê‚≠ê | ‚≠ê‚≠ê‚≠ê |
| Multi-Agent | 5000+ | 3K | ‚≠ê‚≠ê | ‚≠ê‚≠ê‚≠ê‚≠ê‚≠ê | ‚≠ê‚≠ê |

### Alternativas Rejeitadas

#### ‚ùå Multi-Agent System (agent por dom√≠nio)
- **Pr√≥s:** Especializa√ß√£o m√°xima, paraleliza√ß√£o poss√≠vel
- **Contras:** Overhead de coordena√ß√£o, hard to debug, complexo demais
- **Decis√£o:** Overkill exceto para >5000 tabelas

#### ‚ùå LLM gera SQL sem ver schema
- **Pr√≥s:** Zero overhead de retrieval
- **Contras:** Taxa de erro ~40% (testado), SQL inv√°lido frequente
- **Decis√£o:** Rejeitado (precisa do schema)

---

## ADR-004: Logging, Observability e Continuous Improvement

**Data:** 2024-11-24  
**Status:** ‚úÖ REQUISITO para MVP  
**Decisores:** Equipa de Engenharia + Product

### Problema

Como **aprender e melhorar** o sistema baseado em uso real?

**Quest√µes:**
- Quais queries os users fazem mais?
- Que ferramentas s√£o mais usadas?
- Quando o sistema falha?
- Que novas ferramentas criar?

### Decis√£o: Structured Logging de Todas as Intera√ß√µes

#### **Query Log Schema:**

```python
from dataclasses import dataclass
from datetime import datetime
from typing import List, Optional, Dict, Any

@dataclass
class QueryLog:
    # Metadata
    timestamp: datetime
    session_id: str
    
    # Query
    query: str
    intent_type: str  # search, recommendation, unrelated, etc.
    
    # Execution
    tools_called: List[str]  # ["search_products", "get_cooccurrence"]
    tool_arguments: Dict[str, Any]
    used_fallback: bool  # True se usou SQL Agent
    
    # Results
    products_returned: int
    response_time_ms: float
    llm_tokens_used: int
    success: bool
    
    # Feedback (se dispon√≠vel)
    user_feedback: Optional[int]  # 1-5 stars
    user_clicked_product: Optional[int]  # product_id
```

#### **Database Table:**

```sql
CREATE TABLE query_logs (
    id SERIAL PRIMARY KEY,
    timestamp TIMESTAMP NOT NULL DEFAULT NOW(),
    session_id VARCHAR(100),
    
    -- Query
    query TEXT NOT NULL,
    intent_type VARCHAR(50),
    
    -- Execution
    tools_called JSONB,
    tool_arguments JSONB,
    used_fallback BOOLEAN DEFAULT FALSE,
    
    -- Results
    products_returned INT,
    response_time_ms INT,
    llm_tokens_used INT,
    success BOOLEAN,
    
    -- Feedback
    user_feedback INT CHECK (user_feedback BETWEEN 1 AND 5),
    user_clicked_product INT REFERENCES products(product_id)
);

CREATE INDEX idx_query_logs_timestamp ON query_logs(timestamp);
CREATE INDEX idx_query_logs_intent ON query_logs(intent_type);
CREATE INDEX idx_query_logs_success ON query_logs(success);
```

#### **Logging Implementation:**

```python
class QueryTracker:
    def __init__(self):
        self.current_log = None
    
    def start_query(self, query: str, session_id: str):
        self.current_log = QueryLog(
            timestamp=datetime.now(),
            session_id=session_id,
            query=query,
            intent_type=None,  # Preenchido depois
            tools_called=[],
            tool_arguments={},
            used_fallback=False,
            products_returned=0,
            response_time_ms=0,
            llm_tokens_used=0,
            success=False
        )
    
    def log_tool_call(self, tool_name: str, arguments: dict):
        self.current_log.tools_called.append(tool_name)
        self.current_log.tool_arguments[tool_name] = arguments
    
    def finish_query(self, success: bool, products_count: int, elapsed_ms: float):
        self.current_log.success = success
        self.current_log.products_returned = products_count
        self.current_log.response_time_ms = elapsed_ms
        self._save_to_db()
    
    def _save_to_db(self):
        with engine.begin() as conn:
            conn.execute(text("""
                INSERT INTO query_logs 
                (timestamp, session_id, query, intent_type, tools_called, 
                 tool_arguments, used_fallback, products_returned, 
                 response_time_ms, llm_tokens_used, success)
                VALUES 
                (:timestamp, :session_id, :query, :intent, :tools, 
                 :args, :fallback, :count, :time, :tokens, :success)
            """), {
                "timestamp": self.current_log.timestamp,
                "session_id": self.current_log.session_id,
                "query": self.current_log.query,
                "intent": self.current_log.intent_type,
                "tools": json.dumps(self.current_log.tools_called),
                "args": json.dumps(self.current_log.tool_arguments),
                "fallback": self.current_log.used_fallback,
                "count": self.current_log.products_returned,
                "time": self.current_log.response_time_ms,
                "tokens": self.current_log.llm_tokens_used,
                "success": self.current_log.success
            })
```

### M√©tricas a Monitorizar

#### **Operacionais:**
- **Lat√™ncia:** P50, P95, P99 por tipo de query
- **Taxa de sucesso:** % queries que retornam resultados √∫teis
- **Taxa de fallback:** % queries que usam SQL Agent
- **Token usage:** Custo mensal de LLM calls

#### **Produto:**
- **Tool distribution:** Que ferramentas s√£o mais usadas?
- **Intent distribution:** Que tipos de queries s√£o mais comuns?
- **Failed queries:** Que queries falham frequentemente?
- **User satisfaction:** Feedback m√©dio (quando dispon√≠vel)

#### **Continuous Improvement:**
- **Pattern detection:** Queries similares que n√£o t√™m ferramenta dedicada
- **New tool opportunities:** Se 5%+ queries usam fallback para o mesmo padr√£o ‚Üí criar tool
- **A/B testing:** Testar diferentes system prompts, routing strategies

### Dashboard Exemplo

```sql
-- Queries mais comuns sem ferramenta dedicada
SELECT query, COUNT(*) as frequency
FROM query_logs
WHERE used_fallback = TRUE
GROUP BY query
ORDER BY frequency DESC
LIMIT 20;

-- Performance por intent type
SELECT 
    intent_type,
    AVG(response_time_ms) as avg_latency,
    AVG(products_returned) as avg_results,
    AVG(CASE WHEN success THEN 1 ELSE 0 END) as success_rate
FROM query_logs
GROUP BY intent_type;

-- Tool usage distribution
SELECT tool, COUNT(*) as calls
FROM query_logs, jsonb_array_elements_text(tools_called) as tool
GROUP BY tool
ORDER BY calls DESC;
```

### Consequ√™ncias

**Positivas:**
- ‚úÖ Dados para decis√µes baseadas em evid√™ncia
- ‚úÖ Identifica gaps na funcionalidade
- ‚úÖ Permite A/B testing
- ‚úÖ Tracking de custos (tokens)

**Negativas:**
- ‚ùå Overhead de logging (~5-10ms por query)
- ‚ùå Storage costs (mas barato)
- ‚ùå Privacy concerns (armazenar queries dos users)

---

## ADR-005: Security e Rate Limiting

**Data:** 2024-11-24  
**Status:** üìã PLANEAMENTO (Fase 2)

### Problema

Proteger o sistema contra:
- SQL injection (mesmo com function calling)
- Rate limiting abuse
- Prompt injection attacks
- Cost explosion (token usage)

### Decis√£o: Defense in Depth

#### **Layer 1: Input Validation**
```python
def validate_query(query: str) -> bool:
    # Max length
    if len(query) > 500:
        raise ValueError("Query too long")
    
    # No SQL keywords in user input
    dangerous = ["DROP", "DELETE", "UPDATE", "ALTER", "EXEC"]
    if any(word in query.upper() for word in dangerous):
        raise SecurityError("Suspicious input detected")
    
    return True
```

#### **Layer 2: Parameterized Queries Only**
```python
# ‚úÖ SEMPRE usar
conn.execute(text("SELECT * FROM products WHERE id = :id"), {"id": product_id})

# ‚ùå NUNCA fazer
conn.execute(f"SELECT * FROM products WHERE id = {product_id}")
```

#### **Layer 3: Rate Limiting**
```python
from tenacity import retry, stop_after_attempt, wait_exponential

@retry(stop=stop_after_attempt(3), wait=wait_exponential(min=2, max=10))
def call_llm_with_retry(**kwargs):
    return client.chat.completions.create(**kwargs)

# Per-user rate limiting
RATE_LIMITS = {
    "free": {"calls_per_minute": 10, "calls_per_day": 100},
    "premium": {"calls_per_minute": 60, "calls_per_day": 1000}
}
```

#### **Layer 4: Cost Control**
```python
# Token budget por query
MAX_TOKENS_PER_QUERY = 4000

# Alert se custo mensal > threshold
MONTHLY_BUDGET_USD = 500

def check_budget():
    current_spend = get_current_month_spend()
    if current_spend > MONTHLY_BUDGET_USD * 0.8:
        alert_team("Approaching budget limit")
```

---

## Sum√°rio de Decis√µes

| ADR | Decis√£o | Status | Fase | Rationale |
|-----|---------|--------|------|-----------|
| 001 | H√≠brido Function Calling + SQL Agent | ‚úÖ Aceite | MVP: FC only, Prod: H√≠brido | Controlo + Flexibilidade |
| 002 | Text blob minimalista, embeddings Fase 2 | ‚è∏Ô∏è Adiado | MVP: Skip, Prod: Avaliar | Simplicidade, validar necessidade |
| 003 | Schema RAG se >50 tabelas | üìã Planeamento | Futuro | Escalabilidade comprovada |
| 004 | Logging completo de queries | ‚úÖ Requisito | MVP | Aprender e melhorar |
| 005 | Security layers + rate limiting | üìã Planeamento | Fase 2 | Prote√ß√£o essencial |

---

## Refer√™ncias

- **OpenAI Function Calling:** https://platform.openai.com/docs/guides/function-calling
- **LangChain SQL Agent:** https://python.langchain.com/docs/integrations/toolkits/sql_database
- **RAG Patterns:** https://arxiv.org/abs/2005.11401
- **pgvector:** https://github.com/pgvector/pgvector
- **Schema RAG:** https://www.databricks.com/blog/llms-and-sql-databases

---

**√öltima atualiza√ß√£o:** 2024-11-24  
**Pr√≥xima revis√£o:** Ap√≥s MVP launch (baseado em dados reais de uso)
