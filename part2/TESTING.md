# Testing the LLM Agent with Function Calling

## ‚úÖ Implementa√ß√µes Completadas

### 1. **Documento de Arquitetura** (`docs/ARCHITECTURE_DECISIONS.md`)
   - ADR-001: Arquitetura H√≠brida (Function Calling + LangChain SQL Agent)
   - ADR-002: Estrat√©gia de Embeddings e Text Blob
   - ADR-003: Escalabilidade para Milhares de Tabelas
   - ADR-004: Logging e Observabilidade
   - ADR-005: Security e Rate Limiting

### 2. **Core Tools** (`src/recsys/tools.py`)
   - ‚úÖ `search_products()` - Busca com filtros (store, age, franchise, segment)
   - ‚úÖ `get_product_details()` - Detalhes de produto espec√≠fico
   - ‚úÖ `get_cooccurrence_neighbors()` - Produtos comprados juntos
   - ‚úÖ `find_similar_products()` - Produtos similares (usa co-occurrence como proxy)
   - ‚úÖ `get_product_by_name_fuzzy()` - Busca fuzzy por nome

### 3. **Agent com Function Calling** (`src/agent/core.py`)
   - ‚úÖ Agentic loop com OpenAI Function Calling
   - ‚úÖ Decide automaticamente quais ferramentas usar
   - ‚úÖ M√∫ltiplas itera√ß√µes se necess√°rio
   - ‚úÖ Tracking integrado de queries

### 4. **System Prompt Melhorado** (`src/agent/prompts.py`)
   - ‚úÖ Instru√ß√µes claras sobre cada ferramenta
   - ‚úÖ Guidelines de quando usar cada tool
   - ‚úÖ Special cases (unrelated queries, unclear requests, no results)
   - ‚úÖ Limita√ß√µes expl√≠citas

### 5. **Sistema de Logging** (`src/utils/tracking.py`)
   - ‚úÖ QueryLog dataclass
   - ‚úÖ QueryTracker para tracking de queries
   - ‚úÖ M√©tricas: response time, tools usadas, produtos retornados
   - ‚úÖ Estat√≠sticas agregadas

---

## üöÄ Como Testar

### Pr√©-requisitos

1. **OpenAI API Key:**
   ```bash
   export OPENAI_API_KEY="sk-..."
   ```

2. **Ambiente Virtual Ativo:**
   ```bash
   source /home/goncalo/challenge_jta/.venv/bin/activate
   ```

3. **Database Configurada:**
   O sistema espera PostgreSQL com os dados j√° carregados (parte do ETL anterior).

---

### Teste 1: Ferramentas Individuais

```bash
cd /home/goncalo/challenge_jta/part2
python -m src.recsys.tools
```

**Output esperado:**
```
=== Testing recsys/tools.py ===

1. Search products for kids at Store A:
  - Animal Crossing: New Horizons (Age: 3+)
  - Super Mario Odyssey (Age: 7+)
  - Mario Kart 8 Deluxe (Age: 6+)

2. Get details of product ID 1:
  - Animal Crossing: New Horizons
  - Franchise: Animal Crossing
  - Stores: A=500000, B=300000, C=0

3. Products bought with product ID 1:
  - Nintendo Switch Pro Controller (co-occurrence: 200000)
  - Nintendo Switch (co-occurrence: 200000)
  - Joy-Con Controllers (Pair) (co-occurrence: 100000)

4. Fuzzy search for 'Mario':
  - Super Mario Odyssey
  - Mario Kart 8 Deluxe
  - Mario Party Superstars

=== All tests passed! ===
```

---

### Teste 2: Agent com Function Calling

```bash
cd /home/goncalo/challenge_jta/part2
python test_agent.py
```

**Queries testadas:**

1. **Unrelated Query (do README):**
   ```
   "I want a pepperoni pizza with extra cheese please."
   ```
   **Comportamento esperado:** Agent detecta que √© irrelevante e responde educadamente

2. **Simple Search:**
   ```
   "I want games for a 5 year old child at Store A"
   ```
   **Comportamento esperado:** Usa `search_products(store="Store A", max_age=5)`

3. **Complex Query (do README):**
   ```
   "I want to buy a game for my nephew, at Store A, who is 5 years old.
    We loved Super Mario Odyssey, but I cannot buy a game from this family 
    as he already has all Super Mario games."
   ```
   **Comportamento esperado:**
   - Usa `get_product_by_name_fuzzy("Super Mario Odyssey")` para encontrar o ID
   - Usa `get_cooccurrence_neighbors(product_id)` para encontrar jogos comprados juntos
   - Usa `search_products(store="Store A", max_age=5, exclude_franchise="Super Mario")`
   - Combina resultados e recomenda

4. **Similar Products:**
   ```
   "What games are similar to Animal Crossing?"
   ```
   **Comportamento esperado:**
   - Usa `get_product_by_name_fuzzy("Animal Crossing")`
   - Usa `find_similar_products(product_id)`

**Output esperado:**
```
============================================================
TESTING AGENT WITH FUNCTION CALLING
============================================================

...

============================================================
QUERY TRACKER STATISTICS
============================================================
Total Queries: 4
Success Rate: 100.0%
Avg Response Time: 2500ms
Avg Products Returned: 8.5
Fallback Usage: 0.0%

Tool Usage:
  - search_products: 3 calls
  - get_product_by_name_fuzzy: 2 calls
  - get_cooccurrence_neighbors: 1 call
  - find_similar_products: 1 call
============================================================
```

---

### Teste 3: Tracking System

```bash
cd /home/goncalo/challenge_jta/part2
python -m src.utils.tracking
```

**Output esperado:**
```
Testing QueryTracker...

============================================================
QUERY TRACKER STATISTICS
============================================================
Total Queries: 2
Success Rate: 100.0%
Avg Response Time: 182ms
Avg Products Returned: 2.5
Fallback Usage: 0.0%

Tool Usage:
  - search_products: 1 calls
============================================================

‚úì QueryTracker test completed
```

---

## üìä Verificar Dados no Banco

Para verificar se os logs est√£o sendo salvos:

```sql
-- Ver √∫ltimas queries
SELECT * FROM query_logs ORDER BY timestamp DESC LIMIT 10;

-- Estat√≠sticas de ferramentas
SELECT 
    jsonb_array_elements_text(tools_called) as tool,
    COUNT(*) as usage_count
FROM query_logs
GROUP BY tool
ORDER BY usage_count DESC;

-- Performance por sucesso
SELECT 
    success,
    AVG(response_time_ms) as avg_time,
    COUNT(*) as count
FROM query_logs
GROUP BY success;
```

---

## üîç Debugging

Se algo n√£o funcionar:

1. **Erro de m√≥dulo n√£o encontrado:**
   ```bash
   # Certifica-te que est√°s no diret√≥rio correto
   cd /home/goncalo/challenge_jta/part2
   
   # Usa python -m para importar como m√≥dulo
   python -m src.agent.core
   ```

2. **Erro de OpenAI API:**
   ```bash
   # Verifica se a chave est√° definida
   echo $OPENAI_API_KEY
   
   # Se n√£o estiver, define:
   export OPENAI_API_KEY="sk-..."
   ```

3. **Erro de Database:**
   ```bash
   # Testa a conex√£o
   python -m src.utils.test_connection
   ```

4. **Ver logs detalhados:**
   O agent j√° imprime logs detalhados no terminal durante a execu√ß√£o.

---

## üìà Pr√≥ximos Passos (Fase 2)

Conforme documentado em `ARCHITECTURE_DECISIONS.md`:

1. **Embeddings + Vector Search:**
   - Gerar embeddings dos text_blobs (apenas contexto √∫nico)
   - Setup pgvector ou Pinecone
   - Implementar `find_similar_by_embedding()`

2. **LangChain SQL Agent como Fallback:**
   - Adicionar para queries n√£o previstas
   - Logging de fallbacks para criar novas ferramentas

3. **Caching:**
   - Redis para cache de queries frequentes
   - In-memory cache para ferramentas

4. **Melhorias no Text Blob:**
   - Adicionar customer insights reais
   - Store exclusives
   - Cross-sell patterns

5. **Dashboard de Analytics:**
   - Grafana + PostgreSQL
   - M√©tricas em tempo real
   - A/B testing

---

## üìù Notas Importantes

- **MVP Atual:** Function calling puro, sem embeddings (conforme ADR-002)
- **Co-occurrence como proxy:** `find_similar_products()` usa co-occurrence at√© embeddings serem implementados
- **Logging:** Todas as queries s√£o tracked, mas salvar no DB depende da tabela `query_logs` existir
- **Token usage:** Tracking de tokens depende da resposta da OpenAI incluir `usage`

---

## ‚úÖ Checklist de Implementa√ß√£o

- [x] Documento de decis√µes arquiteturais (ARCHITECTURE_DECISIONS.md)
- [x] 5 core tools implementadas e testadas
- [x] Agent com function calling e agentic loop
- [x] System prompt melhorado
- [x] Sistema de logging e tracking
- [x] Testes para unrelated query e complex query
- [ ] Embeddings + Vector search (Fase 2)
- [ ] LangChain SQL Agent fallback (Fase 2)
- [ ] Caching (Fase 2)
- [ ] Dashboard de analytics (Fase 2)

---

**√öltima atualiza√ß√£o:** 2024-11-24  
**Autor:** Implementa√ß√£o baseada nos ADRs documentados
